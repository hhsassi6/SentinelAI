{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ‚á£ √† ex√©cuter une fois au d√©but du notebook\n",
        "%env GROQ_TOKEN=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\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub5oS814fwdD",
        "outputId": "0a7871af-4747-407b-9f85-27570bc70995"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GROQ_TOKEN=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OVctbbOTc4Z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4329d7c3-114c-4e8b-93c5-eab705251788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PDFs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [25:10<00:00, 302.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Rapport g√©n√©r√© : /content/drive/MyDrive/due_diligence_questions.md\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# üìä  Title‚ÄëAware Due‚ÄëDiligence Question Generator  (Colab + Groq)\n",
        "# ==============================================================\n",
        "\n",
        "# ‚ë†  INSTALL  ‚îÄ libs l√©g√®res + openai‚â•1\n",
        "!pip install -q PyMuPDF tqdm regex python-dotenv \"openai>=1.3.7\"\n",
        "\n",
        "# ‚ë°  Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "PDF_DIR = \"/content/drive/MyDrive/DueDilDocuments\"          # dossier PDF\n",
        "OUT_MD  = \"/content/drive/MyDrive/due_diligence_questions.md\"\n",
        "\n",
        "# ‚ë¢  Cl√© & endpoint Groq Cloud  (API style OpenAI v1)\n",
        "import os, json, fitz, regex as re2, tqdm\n",
        "from statistics import quantiles\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]  = \"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\"          # <‚Äë‚Äë remplace\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.groq.com/openai/v1\"\n",
        "\n",
        "client = OpenAI()   # prendra cl√© + base_url depuis les variables d'environnement\n",
        "\n",
        "# ‚ë£  PDF ‚ûú sections (d√©tection de titres)\n",
        "HEAD_RE_CAPS = re2.compile(r\"^[\\p{Lu}0-9 &/‚Äì-]{6,}$\")\n",
        "HEAD_RE_NUM  = re2.compile(r\"^\\d+(\\.\\d+)*\\s+\\S+\")\n",
        "\n",
        "def collect_big_fonts(page):\n",
        "    sizes = [s[\"size\"]\n",
        "             for blk in page.get_text(\"dict\")[\"blocks\"]\n",
        "             for ln  in blk.get(\"lines\", [])\n",
        "             for s   in ln.get(\"spans\", [])]\n",
        "    if not sizes: return set()\n",
        "    thresh = quantiles(sizes, n=10)[-1]\n",
        "    return {s for s in sizes if s >= thresh}\n",
        "\n",
        "def lines_with_fonts(page):\n",
        "    for blk in page.get_text(\"dict\")[\"blocks\"]:\n",
        "        for ln in blk.get(\"lines\", []):\n",
        "            txt = \"\".join(sp[\"text\"] for sp in ln[\"spans\"]).strip()\n",
        "            if txt:\n",
        "                yield txt, max(sp[\"size\"] for sp in ln[\"spans\"])\n",
        "\n",
        "def split_by_titles(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    sections, buf, head = [], [], \"INTRODUCTION\"\n",
        "    for page in doc:\n",
        "        big = collect_big_fonts(page)\n",
        "        for txt, sz in lines_with_fonts(page):\n",
        "            looks_head = (\n",
        "                sz in big or txt.endswith(\":\") or\n",
        "                HEAD_RE_CAPS.match(txt) or HEAD_RE_NUM.match(txt)\n",
        "            ) and len(txt.split()) <= 15\n",
        "            if looks_head:\n",
        "                if buf:\n",
        "                    sections.append((head, \"\\n\".join(buf).strip()))\n",
        "                    buf = []\n",
        "                head = txt.rstrip(\":\")\n",
        "            else:\n",
        "                buf.append(txt)\n",
        "    if buf:\n",
        "        sections.append((head, \"\\n\".join(buf).strip()))\n",
        "    return sections\n",
        "\n",
        "# ‚ë§  LLM helpers (Groq : mod√®le Mixtral‚Äë8√ó7B)\n",
        "LABELS = [\"AML / KYC\",\"Fund Regulation\",\"Market Manipulation\",\n",
        "          \"Stablecoins\",\"Custody & Wallet Security\",\n",
        "          \"Liquidity\",\"Tokenomics\",\"Tax & Reporting\"]\n",
        "\n",
        "def gen_questions(passage:str, k:int=5):\n",
        "    prompt = (\"Act like a senior compliance officer, understand deeply this document \"\n",
        "              \"and generate the questions that I need to ask to generate a due diligence report:\\n\\n\"\n",
        "              f\"{passage}\\n\\nPlease provide {k} critical questions, one per line.\")\n",
        "\n",
        "    rsp = client.chat.completions.create(\n",
        "        model=\"gemma2-9b-it\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        max_tokens=300, temperature=0.7\n",
        "    )\n",
        "    raw = rsp.choices[0].message.content\n",
        "    qs  = [re2.sub(r\"^[\\-\\d\\.\\)\\s]*\",\"\",l).strip()\n",
        "           for l in raw.splitlines() if l.strip()]\n",
        "    return [q.rstrip(\".\")+\"?\" if not q.endswith(\"?\") else q for q in qs][:k]\n",
        "\n",
        "def bucket(qs:list[str]):\n",
        "    if not qs: return {}\n",
        "    results = {l:[] for l in LABELS}\n",
        "\n",
        "    for q in qs:\n",
        "        prompt = (f\"Act like a senior compliance officer. Choose ONLY ONE of these categories for the following question: \"\n",
        "                  f\"{', '.join(LABELS)}.\\n\\nQuestion: {q}\\n\\n\"\n",
        "                  f\"Reply with just the category name, nothing else.\")\n",
        "\n",
        "        try:\n",
        "            rsp = client.chat.completions.create(\n",
        "                model=\"gemma2-9b-it\",\n",
        "                messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "                temperature=0,\n",
        "                max_tokens=50  # Keep response short\n",
        "            )\n",
        "\n",
        "            category = rsp.choices[0].message.content.strip()\n",
        "\n",
        "            # Find the best matching category\n",
        "            matched_category = None\n",
        "            for label in LABELS:\n",
        "                if label.lower() in category.lower():\n",
        "                    matched_category = label\n",
        "                    break\n",
        "\n",
        "            # If no match found, use the closest match\n",
        "            if not matched_category:\n",
        "                for label in LABELS:\n",
        "                    if any(word.lower() in category.lower() for word in label.split()):\n",
        "                        matched_category = label\n",
        "                        break\n",
        "\n",
        "            # If still no match, assign to first category\n",
        "            if not matched_category and LABELS:\n",
        "                matched_category = LABELS[0]\n",
        "\n",
        "            # Add question to the matched category\n",
        "            if matched_category:\n",
        "                results[matched_category].append(q)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing question: {q}\")\n",
        "            print(f\"Error: {e}\")\n",
        "            # Continue with next question\n",
        "\n",
        "    return {k:v for k,v in results.items() if v}\n",
        "\n",
        "# ‚ë•  Pipeline dossier PDF - THIS FUNCTION WAS MISSING\n",
        "def run_dir(pdf_dir):\n",
        "    rows=[]\n",
        "    for pdf in tqdm.tqdm(list(Path(pdf_dir).glob(\"*.pdf\")), desc=\"PDFs\"):\n",
        "        for idx,(title,body) in enumerate(split_by_titles(pdf),1):\n",
        "            if len(body.split())<40: continue\n",
        "            qs = gen_questions(body,5)\n",
        "            bk = bucket(qs)\n",
        "            if bk: rows.append((pdf.name,idx,title,bk))\n",
        "    return rows\n",
        "\n",
        "def write_md(rows,outfile):\n",
        "    with open(outfile,\"w\",encoding=\"utf-8\") as f:\n",
        "        for pdf,idx,title,bk in rows:\n",
        "            f.write(f\"## {pdf} ‚Äì Section {idx}: {title}\\n\\n\")\n",
        "            for cat,qs in bk.items():\n",
        "                f.write(f\"### {cat}\\n\")\n",
        "                for q in qs: f.write(f\"- {q}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            f.write(\"\\n---\\n\\n\")\n",
        "\n",
        "# ‚ë¶  Ex√©cution\n",
        "rows = run_dir(PDF_DIR)\n",
        "write_md(rows, OUT_MD)\n",
        "print(\"‚úÖ Rapport g√©n√©r√© :\", OUT_MD)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PH5yJLRfvIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}